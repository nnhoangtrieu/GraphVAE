{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset \n",
    "import torch_geometric\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.data import Dataset as gDataset\n",
    "from torch_geometric.data import Data as gData \n",
    "from torch_geometric.loader import DataLoader as gDataLoader\n",
    "from torch_geometric.datasets import QM9, ZINC\n",
    "from tqdm import tqdm \n",
    "import rdkit\n",
    "from rdkit.Chem import MolFromSmiles as get_mol\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix as get_mat\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smi(path) :\n",
    "    with open(path, 'r') as file :\n",
    "        contents = file.readlines() \n",
    "    smi_list = [content[:-1] for content in contents]\n",
    "    return smi_list\n",
    "\n",
    "def get_coor(path) :\n",
    "    coor_list = []\n",
    "    supplier = rdkit.Chem.SDMolSupplier(path)\n",
    "    for mol in supplier:\n",
    "        coor = []\n",
    "        if mol is not None:\n",
    "            conformer = mol.GetConformer()\n",
    "            for atom in mol.GetAtoms():\n",
    "                atom_idx = atom.GetIdx()\n",
    "                x, y, z = conformer.GetAtomPosition(atom_idx)\n",
    "                coor_atom = list((x,y,z))\n",
    "                coor.append(coor_atom)\n",
    "        coor_list.append(coor)\n",
    "\n",
    "    # Replace invalid idx\n",
    "    for i, coor in enumerate(coor_list):\n",
    "        \n",
    "        if len(coor) == 0 :\n",
    "            if i == 0 :\n",
    "                coor_list = coor_list[1:]\n",
    "            coor_list[i] = coor_list[i-1]\n",
    "    return coor_list\n",
    "\n",
    "def get_edge_index(mol) :\n",
    "    edge_indices, begin, end = [], [], []\n",
    "\n",
    "    for bond in mol.GetBonds() :\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx() \n",
    "        begin.append(i), end.append(j)\n",
    "\n",
    "    for bond in mol.GetBonds() :\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        begin.append(j), end.append(i)\n",
    "    edge_indices.append(begin), edge_indices.append(end)\n",
    "\n",
    "    return torch.tensor(edge_indices)\n",
    "\n",
    "def get_edge_features( mol) :\n",
    "    all_edge_feats = [] \n",
    "\n",
    "    for bond in mol.GetBonds() :\n",
    "        edge_feats = []\n",
    "\n",
    "        edge_feats.append(bond.GetBondType())\n",
    "        all_edge_feats.append(edge_feats)\n",
    "    \n",
    "    for bond in mol.GetBonds() :\n",
    "        edge_feats = []\n",
    "\n",
    "        edge_feats.append(bond.GetBondType())\n",
    "        all_edge_feats.append(edge_feats)\n",
    "\n",
    "    all_edge_feats = np.asarray(all_edge_feats)\n",
    "    return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "def get_node_features(mol) :\n",
    "    all_node_feats = [] \n",
    "\n",
    "    for atom in mol.GetAtoms() :\n",
    "        node_feats = []\n",
    "        node_feats.append(atom.GetAtomicNum())\n",
    "        node_feats.append(atom.GetDegree())\n",
    "        node_feats.append(atom.GetFormalCharge())\n",
    "        node_feats.append(atom.GetHybridization())\n",
    "        node_feats.append(atom.GetIsAromatic())\n",
    "        node_feats.append(atom.GetTotalNumHs())\n",
    "        node_feats.append(atom.GetNumRadicalElectrons())\n",
    "        node_feats.append(atom.IsInRing())\n",
    "        node_feats.append(atom.GetChiralTag())\n",
    "\n",
    "        all_node_feats.append(node_feats)\n",
    "\n",
    "    all_node_feats = np.asarray(all_node_feats)\n",
    "    return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "def count_atoms(smi):\n",
    "    mol = rdkit.Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        num_atoms = mol.GetNumAtoms()\n",
    "        return num_atoms\n",
    "    else:\n",
    "        print(\"Error: Unable to parse SMILES string.\")\n",
    "        return None\n",
    "\n",
    "def get_atom(smi) :\n",
    "    mol = get_mol(smi) \n",
    "    atom_list = [x.GetSymbol() for x in mol.GetAtoms()]\n",
    "    return atom_list\n",
    "\n",
    "def get_bond(smi) :\n",
    "    mol = get_mol(smi) \n",
    "    bond_list = [x.GetBondType() for x in mol.GetBonds()]\n",
    "    return bond_list \n",
    "\n",
    "def get_atom_mat(smi, max_atom) :\n",
    "    atom_list = get_atom(smi) \n",
    "    mat = get_mat(get_mol(smi))\n",
    "    wmat = np.zeros((max_atom, max_atom))\n",
    "    for i, (m, w) in enumerate(zip(mat, wmat)) :\n",
    "        ones = np.where(m == 1)[0]\n",
    "\n",
    "        for idx in ones :\n",
    "            wmat[i][idx] = atom_dic[atom_list[idx]]\n",
    "    return torch.tensor(wmat, dtype = torch.long)\n",
    "\n",
    "def get_bond_mat(smi, max_atom) :\n",
    "    mol = get_mol(smi) \n",
    "    mat = get_mat(mol)\n",
    "\n",
    "    wmat = np.zeros((max_atom, max_atom))\n",
    "\n",
    "    for bond in mol.GetBonds() :\n",
    "        b, e = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "\n",
    "        wmat[b][e] = bond_dic[str(bond.GetBondType())]\n",
    "        wmat[e][b] = bond_dic[str(bond.GetBondType())]\n",
    "\n",
    "    return torch.tensor(wmat, dtype = torch.long)\n",
    "\n",
    "def get_dic(smi_list) :\n",
    "    a_dic, b_dic, i, j  = {}, {}, 1, 1 \n",
    "\n",
    "    for smi in smi_list :\n",
    "        mol = get_mol(smi) \n",
    "        for atom in mol.GetAtoms() :\n",
    "            symbol = atom.GetSymbol() \n",
    "            if symbol not in a_dic : \n",
    "                a_dic[symbol] = i; i += 1\n",
    "\n",
    "        for bond in mol.GetBonds() :\n",
    "            bond_type = str(bond.GetBondType())\n",
    "            if bond_type not in b_dic : \n",
    "                b_dic[bond_type] = j; j += 1 \n",
    "    return a_dic, b_dic \n",
    "    \n",
    "\n",
    "def pad_bond(tensor, max_atom) :\n",
    "    row, col = tensor.size() \n",
    "    pad = torch.cat((tensor, torch.zeros(row, max_atom - col)), dim = 1)\n",
    "    pad = torch.cat((pad, torch.zeros(max_atom - row, pad.size(1))), dim = 0)\n",
    "    return pad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_list = get_smi('./data/raw/ADAGRASIB_SMILES.txt')\n",
    "atom_dic, bond_dic = get_dic(smi_list)\n",
    "atom_dic['None'] = 0 \n",
    "bond_dic['None'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(gData) :\n",
    "    def __cat_dim__(self, key, value, *args, **kwargs):\n",
    "        if key == 'atom_mat' or key == 'bond_mat':\n",
    "            return None\n",
    "        return super().__cat_dim__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(gDataset) : \n",
    "    def __init__(self, root, filename, transform = None, pre_transform = None) :\n",
    "        self.filename = filename \n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) :\n",
    "        return self.filename \n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) :\n",
    "        self.smi_list = get_smi(self.raw_paths[0])\n",
    "        return [f'data_{i}.pt' for i in range(len(self.smi_list))]\n",
    "    \n",
    "    def download(self) : pass \n",
    "\n",
    "    def process(self) :\n",
    "        smi_list = get_smi(self.raw_paths[0])\n",
    "        atom_dic = get_dic(smi_list) \n",
    "        \n",
    "        max_atom = count_atoms(max(smi_list, key = lambda x : count_atoms(x)))\n",
    "        atom_mat_list = [get_wmat(smi, max_atom) for smi in smi_list]\n",
    "        bond_mat_list = [get_bond_mat(smi, max_atom) for smi in smi_list]\n",
    "\n",
    "        for i, smi in enumerate(tqdm(smi_list, total=len(smi_list))) :\n",
    "            mol = get_mol(smi) \n",
    "\n",
    "            node_feat = get_node_features(mol)\n",
    "            edge_idx = get_edge_index(mol)\n",
    "            edge_attr = get_edge_features(mol)\n",
    "\n",
    "            data = MyData(x = node_feat,\n",
    "                        edge_index = edge_idx,\n",
    "                        edge_attr=edge_attr,\n",
    "                        atom_mat = atom_mat_list[i],\n",
    "                        bond_mat = bond_mat_list[i])\n",
    "\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{i}.pt'))\n",
    "\n",
    "\n",
    "    def len(self) :\n",
    "        return len(self.smi_list)\n",
    "    \n",
    "    def get(self, idx) :\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 4255/4255 [00:15<00:00, 271.76it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(root='data', filename=['ADAGRASIB_SMILES.txt'])\n",
    "train_loader = gDataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module) :\n",
    "    def __init__(self, dim_latent) :\n",
    "        super(VAE, self).__init__()\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "        self.gc1 = gnn.GCNConv(9, 128)\n",
    "        self.gc1_bn = nn.BatchNorm1d(128)\n",
    "        self.gc2 = gnn.GCNConv(128, 128) \n",
    "        self.gc2_bn = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.ff1 = nn.Linear(128, 128) \n",
    "        self.ff1_bn = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.mu = nn.Linear(128, dim_latent)\n",
    "        self.sigma = nn.Linear(128, dim_latent) \n",
    "    \n",
    "        self.a_emb = nn.Embedding(len(atom_dic), 128) \n",
    "        self.b_emb = nn.Embedding(len(bond_dic), 128)\n",
    "\n",
    "        self.a_seq = nn.Sequential(\n",
    "            nn.Linear(dim_latent, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, len(atom_dic))\n",
    "        )\n",
    "\n",
    "        self.b_seq = nn.Sequential(\n",
    "            nn.Linear(dim_latent, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, len(bond_dic))\n",
    "        )\n",
    "    def encode(self, input) :\n",
    "        x, edge_index, batch, atom_mat, bond_mat = input.x, input.edge_index, input.batch, input.atom_mat, input.bond_mat\n",
    "\n",
    "\n",
    "        atom_mat = self.a_emb(atom_mat) \n",
    "        bond_mat = self.b_emb(bond_mat) \n",
    "\n",
    "        x = self.gc1(x, edge_index)\n",
    "        x = F.relu(self.gc1_bn(x))\n",
    "        x = self.gc2(x, edge_index)\n",
    "        x = F.relu(self.gc2_bn(x))\n",
    "        x = gnn.global_add_pool(x, batch) \n",
    "        x = self.ff1(x) \n",
    "        x = F.relu(self.ff1_bn(x))\n",
    "        \n",
    "        x = x.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        x = x + atom_mat + bond_mat\n",
    "        \n",
    "        mu, sigma = self.mu(x), self.sigma(x) \n",
    "\n",
    "        z = mu + sigma * self.N.sample(mu.shape)\n",
    "\n",
    "        self.kl = (sigma ** 2 + mu ** 2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        return z \n",
    "\n",
    "    def decode(self, z) :\n",
    "        atom_mat, bond_mat = self.a_seq(z), self.b_seq(z) \n",
    "        return atom_mat, bond_mat\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        z = self.encode(x) \n",
    "        atom_mat, bond_mat = self.decode(z)\n",
    "        \n",
    "        return atom_mat, bond_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 22, 22, 13])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader :\n",
    "    a_mat, b_mat = model(i)\n",
    "    print(a_mat.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1138, -0.3743, -0.3067,  0.1735, -1.2267])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3684060/903835295.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2349, 0.1810, 0.1937, 0.3131, 0.0772])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
